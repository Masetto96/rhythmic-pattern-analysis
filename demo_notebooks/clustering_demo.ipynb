{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering beats and fills on Expanded Groove Midi Dataset\n",
    "*https://magenta.tensorflow.org/datasets/e-gmd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join('..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mirdata\n",
    "import librosa\n",
    "import itertools\n",
    "import umap\n",
    "import umap.plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scripts.data_loaders import load_malian_jembe_dataset, load_candombe_dataset, load_cretan_dances_dataset, load_ballroom_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scripts.scale_transform_magnitude import compute_stm\n",
    "from scripts.clusterers import select_best_num_clusters\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration summary in seconds: \n",
      " count    12254.000000\n",
      "mean       117.741629\n",
      "std         84.448684\n",
      "min         30.219297\n",
      "25%         47.978141\n",
      "50%         96.608073\n",
      "75%        159.605215\n",
      "max        611.754989\n",
      "Name: duration, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "rock             3912\n",
       "latin            1720\n",
       "funk             1505\n",
       "jazz             1376\n",
       "soul             1032\n",
       "hiphop            817\n",
       "neworleans        387\n",
       "afrocuban         301\n",
       "pop               301\n",
       "dance             215\n",
       "reggae            172\n",
       "afrobeat          172\n",
       "punk              129\n",
       "country            86\n",
       "blues              43\n",
       "middleeastern      43\n",
       "gospel             43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean metadata\n",
    "metadata = pd.read_csv(\n",
    "    \"../datasets/e-gmd-v1.0.0/e-gmd-v1.0.0.csv\"\n",
    ")  # read metadata of extended groove midi\n",
    "\n",
    "metadata_beats = metadata[metadata[\"beat_type\"] == \"beat\"]  # select only beats\n",
    "\n",
    "metadata_beats = metadata_beats[metadata_beats[\"duration\"] >= 30]\n",
    "print(\"duration summary in seconds: \\n\", metadata_beats[\"duration\"].describe())\n",
    "\n",
    "metadata_beats[\"genre\"] = metadata_beats[\"style\"].apply(\n",
    "    lambda x: x.split(\"/\")[0]\n",
    ")  # create genre column based on style\n",
    "\n",
    "metadata_beats = metadata_beats[[\"genre\", \"style\", \"audio_filename\", \"duration\"]] # get rid of unnecessary columns\n",
    "metadata_beats = metadata_beats.reset_index(drop=True) # resetting index is neede for interactive plot\n",
    "\n",
    "metadata_beats.genre.unique()\n",
    "metadata_beats.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "rock         5203\n",
       "funk         4472\n",
       "hiphop       2494\n",
       "afrocuban    2236\n",
       "jazz         2193\n",
       "punk         2193\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting occurrences of each genre\n",
    "genre_counts = metadata_beats['genre'].value_counts()\n",
    "\n",
    "# Identifying the top n most frequent genres\n",
    "top_n_genres = genre_counts.head(6).index\n",
    "\n",
    "metadata_beats = metadata_beats[metadata_beats['genre'].isin(top_n_genres)]\n",
    "\n",
    "metadata_beats.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 640/10362 [01:49<27:48,  5.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(metadata_beats\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), total\u001b[38;5;241m=\u001b[39mmetadata_beats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]): \u001b[38;5;66;03m# TODO: find a more efficient way to loop\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# TODO: segment audio file?\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m         y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroove_midi_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m      9\u001b[0m             compute_stm(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     10\u001b[0m         ) \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/internship/rythmic-pattern-analysis/.rhythm/lib/python3.11/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[0;32m~/internship/rythmic-pattern-analysis/.rhythm/lib/python3.11/site-packages/librosa/core/audio.py:222\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    219\u001b[0m         frame_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# Load the target number of frames, and transpose to match librosa form\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43msf_desc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, sr_native\n",
      "File \u001b[0;32m~/internship/rythmic-pattern-analysis/.rhythm/lib/python3.11/site-packages/soundfile.py:895\u001b[0m, in \u001b[0;36mSoundFile.read\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[1;32m    894\u001b[0m         frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[0;32m--> 895\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m>\u001b[39m frames:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/internship/rythmic-pattern-analysis/.rhythm/lib/python3.11/site-packages/soundfile.py:1344\u001b[0m, in \u001b[0;36mSoundFile._array_io\u001b[0;34m(self, action, array, frames)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39msizeof(ctype)\n\u001b[1;32m   1343\u001b[0m cdata \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mcast(ctype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, array\u001b[38;5;241m.\u001b[39m__array_interface__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/internship/rythmic-pattern-analysis/.rhythm/lib/python3.11/site-packages/soundfile.py:1353\u001b[0m, in \u001b[0;36mSoundFile._cdata_io\u001b[0;34m(self, action, data, ctype, frames)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1352\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m action \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ctype)\n\u001b[0;32m-> 1353\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m _error_check(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorcode)\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# preparing the data and computing stm\n",
    "groove_midi_path = Path(\"../datasets/e-gmd-v1.0.0\")\n",
    "features = []\n",
    "for row in tqdm(metadata_beats.itertuples(index=False), total=metadata_beats.shape[0]): # TODO: find a more efficient way to loop\n",
    "    try:\n",
    "        # TODO: segment audio file?\n",
    "        y, sr = librosa.load(groove_midi_path / row.audio_filename, sr=None, duration=30)\n",
    "        features.append(\n",
    "            compute_stm(y=y, sr=sr)\n",
    "        ) \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering and Silhouette analysis\n",
    "*https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py*\n",
    "\n",
    "The plot on the left-hand side displays the silhouette score. The silhouette score measures how similar an object is to its own cluster compared to other clusters. \n",
    "\n",
    "A high silhouette score indicates that clusters are well-separated, while a low score suggests overlapping clusters or misclassification.\n",
    "\n",
    "From the thickness of the silhouette plot the cluster size can be visualized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_clusters = [i for i in range(3, 8)]\n",
    "results, optimal_k = select_best_num_clusters(\n",
    "    n_clusters=num_of_clusters, X=np.array(features), dim_reduction=\"tsne\", cluster_method=\"kmedoids\"\n",
    ")\n",
    "\n",
    "print(f\"Best number of clusters: {optimal_k}; silhouette score: {results.get(optimal_k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data with interactive UMAP plot\n",
    "\n",
    "*https://umap-learn.readthedocs.io/en/latest/plotting.html#interactive-plotting-and-hover-tools*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.factorize(metadata_beats[\"genre\"])[0]  # integer labels needed for the interactive plot\n",
    "reducer = umap.UMAP(metric=\"cosine\").fit(features)  # reduce dimensionality\n",
    "\n",
    "p = umap.plot.interactive(\n",
    "    reducer, labels=labels, hover_data=metadata_beats, point_size=3,\n",
    ")  # interactive plot, hover_data can be customized\n",
    "\n",
    "umap.plot.output_file(\"groove_midi_beats.html\") # save the plot locally\n",
    "umap.plot.output_notebook() # display inline in notebook\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Clustering on Candombe, Malian Jembè, GreekDances, Ballroom and Cuban Salsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters to compute scale transform magnitude\n",
    "stm_params = {\"mel_flag\" : True, \"with_padding\" : True, \"n_mels\" : 50, \"autocor_window_type\" : \"hamming\", \"num_stm_coefs\" : 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mj, labels_mj, hover_data_mj = load_malian_jembe_dataset(stm_params=stm_params)\n",
    "hover_data_mj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_candombe, labels_candombe, hover_data_candombe = load_candombe_dataset(stm_params=stm_params)\n",
    "hover_data_candombe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cretan, labels_cretan, hover_data_cretan = load_cretan_dances_dataset(stm_params=stm_params)\n",
    "hover_data_cretan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ballroom, labels_ballroom, hover_data_ballroom = load_ballroom_dataset(stm_params=stm_params)\n",
    "hover_data_ballroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = list(itertools.chain(features_mj, features_candombe, features_cretan, features_ballroom))\n",
    "combined_labels = list(itertools.chain(hover_data_mj[\"label\"], hover_data_candombe[\"label\"], hover_data_cretan[\"label\"], hover_data_ballroom[\"label\"]))\n",
    "combined_hover_data = pd.concat([hover_data_mj, hover_data_candombe, hover_data_cretan, hover_data_ballroom]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering and Silhouette analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_clusters = [i for i in range(3, 5)]\n",
    "results, optimal_k = select_best_num_clusters(\n",
    "    n_clusters=num_of_clusters, X=np.array(combined_features), dim_reduction=\"tsne\", cluster_method=\"kmedoids\"\n",
    ")\n",
    "\n",
    "print(f\"Best number of clusters: {optimal_k}; silhouette score: {results.get(optimal_k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data with interactive UMAP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = LabelEncoder().fit_transform(combined_labels)  # integer labels needed for the interactive plot\n",
    "reducer = umap.UMAP(metric=\"cosine\").fit(combined_features) # https://umap-learn.readthedocs.io/en/latest/parameters.html#basic-umap-parameters\n",
    "\n",
    "p = umap.plot.interactive(\n",
    "    reducer, labels=encoded_labels, hover_data=combined_hover_data, point_size=5,\n",
    ")  # interactive plot, hover_data can be customized\n",
    "\n",
    "# umap.plot.output_file(\"mj.html\") # save the plot locally\n",
    "umap.plot.output_notebook() # display inline in notebook\n",
    "umap.plot.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rhythm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
